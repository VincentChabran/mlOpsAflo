# ğŸš• NYC Taxi Trip Duration Prediction

Ce projet prÃ©dit la durÃ©e des trajets en taxi Ã  New York en utilisant des modÃ¨les de Machine Learning. Il est entiÃ¨rement automatisÃ© avec des scripts Bash et propose une API FastAPI ainsi qu'une interface utilisateur Streamlit.

---

## ğŸ“‚ **Architecture du projet**

```
nyc_taxi_trip/
â”‚â”€â”€ api/                      # ğŸ“‚ Code source de l'API FastAPI
â”‚   â”œâ”€â”€ main.py               # ğŸŒ API pour servir les prÃ©dictions
â”‚
â”‚â”€â”€ data/                     # ğŸ“‚ DonnÃ©es brutes et prÃ©dictions
â”‚   â”œâ”€â”€ train.csv              # ğŸ“„ DonnÃ©es d'entraÃ®nement
â”‚   â”œâ”€â”€ test.csv               # ğŸ“„ DonnÃ©es de test
â”‚   â”œâ”€â”€ predictions.csv        # ğŸ“„ RÃ©sultats des prÃ©dictions
â”‚   â”œâ”€â”€ nyc_taxi.zip           # ğŸ“¦ Archive des donnÃ©es (optionnel)
â”‚
â”‚â”€â”€ models/                    # ğŸ“‚ ModÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ taxi_model.pkl         # ğŸ¤– ModÃ¨le sauvegardÃ©
â”‚
â”‚â”€â”€ notebooks/                  # ğŸ“‚ Analyses exploratoires
â”‚   â”œâ”€â”€ EDA.ipynb              # ğŸ“Š Notebook d'analyse des donnÃ©es
â”‚
â”‚â”€â”€ scripts/                    # ğŸ“‚ Scripts d'automatisation
â”‚   â”œâ”€â”€ setup_env.sh            # ğŸ›  Installation des dÃ©pendances et environnement
â”‚   â”œâ”€â”€ extract_data.sh         # ğŸ“‚ Extraction des donnÃ©es et stockage SQLite
â”‚   â”œâ”€â”€ train_model.sh          # ğŸ¯ EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ run_inference.sh        # ğŸ¤– ExÃ©cution de l'infÃ©rence
â”‚   â”œâ”€â”€ start_api.sh            # ğŸŒ DÃ©marrage de FastAPI
â”‚   â”œâ”€â”€ start_ui.sh             # ğŸ–¥ DÃ©marrage de Streamlit UI
â”‚   â”œâ”€â”€ run_ml_pipeline.sh      # ğŸš€ ExÃ©cute tout le pipeline Machine Learning
â”‚   â”œâ”€â”€ run_api_ui.sh           # ğŸŒ DÃ©marre lâ€™API et lâ€™UI en parallÃ¨le
â”‚
â”‚â”€â”€ src/                        # ğŸ“‚ Code source du projet
â”‚   â”œâ”€â”€ fetch_and_store.py      # ğŸ—„ Stockage des donnÃ©es dans SQLite
â”‚   â”œâ”€â”€ preprocessing.py        # ğŸ”„ Nettoyage et transformation des donnÃ©es
â”‚   â”œâ”€â”€ train.py                # ğŸ¯ EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ inference.py            # ğŸ” PrÃ©dictions sur les nouvelles donnÃ©es
â”‚   â”œâ”€â”€ utils.py                # ğŸ›  Fonctions utilitaires
â”‚
â”‚â”€â”€ ui/                         # ğŸ“‚ Interface utilisateur avec Streamlit
â”‚   â”œâ”€â”€ app.py                  # ğŸ–¥ Interface web utilisateur
â”‚
â”‚â”€â”€ config.yml                  # âš™ï¸ Configuration du projet
â”‚â”€â”€ requirements.txt             # ğŸ“¦ DÃ©pendances Python
â”‚â”€â”€ README.md                    # ğŸ“– Documentation du projet
```

---

## ğŸš€ **Comment exÃ©cuter le projet ?**

### ğŸ“Œ **PrÃ©requis**

-  **Python 3.11+**
-  **Conda** (installÃ© via [Miniconda](https://docs.conda.io/en/latest/miniconda.html))
-  **Git**

### ğŸ“¥ **1. Cloner le repo et entrer dans le dossier**

```bash
git clone https://github.com/ton-user/nyc_taxi_trip.git
cd nyc_taxi_trip
```

### ğŸ›  **2. Installer l'environnement et les dÃ©pendances**

```bash
bash scripts/setup_env.sh
```

Si l'environnement existe dÃ©jÃ , il ne sera pas recrÃ©Ã©.

### ğŸ“‚ **3. Extraire les donnÃ©es et les stocker dans SQLite**

```bash
bash scripts/extract_data.sh
```

### ğŸ¯ **4. EntraÃ®ner le modÃ¨le et exÃ©cuter l'infÃ©rence**

```bash
bash scripts/run_ml_pipeline.sh
```

### ğŸŒ **5. Lancer l'API et l'interface utilisateur**

```bash
bash scripts/run_api_ui.sh
```

---

## ğŸ“Š **Exploration des donnÃ©es**

Si vous souhaitez analyser les donnÃ©es avant l'entraÃ®nement, ouvrez le notebook :

```bash
jupyter notebook notebooks/EDA.ipynb
```

---

## ğŸ” **Fichiers principaux et leur rÃ´le**

| Fichier              | Description                                          |
| -------------------- | ---------------------------------------------------- |
| `train.py`           | EntraÃ®ne le modÃ¨le de prÃ©diction                     |
| `inference.py`       | PrÃ©dit la durÃ©e des trajets sur de nouvelles donnÃ©es |
| `fetch_and_store.py` | Stocke les donnÃ©es dans SQLite                       |
| `preprocessing.py`   | Nettoie et prÃ©pare les donnÃ©es pour l'entraÃ®nement   |
| `setup_env.sh`       | Installe l'environnement et les dÃ©pendances          |
| `extract_data.sh`    | DÃ©compresse les donnÃ©es ZIP et stocke dans SQLite    |
| `run_ml_pipeline.sh` | ExÃ©cute tout le pipeline Machine Learning            |
| `run_api_ui.sh`      | DÃ©marre lâ€™API et lâ€™interface utilisateur             |

---

## ğŸ“Œ **AmÃ©liorations possibles**

-  ğŸ”„ **Optimisation du modÃ¨le** : Essayer d'autres algorithmes (XGBoost, LGBM, etc.)
-  ğŸš€ **DÃ©ploiement en production** : HÃ©berger l'API sur un serveur cloud
-  ğŸ” **Ajout de monitoring** : Suivi des performances en temps rÃ©el

---

## ğŸ“ **Support et contact**

Si vous avez des questions, ouvrez une issue sur le repo GitHub ! ğŸ˜Š

ğŸ¯ **Bon Machine Learning !** ğŸš€
